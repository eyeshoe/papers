Title: Who let the dogs out? Modeling Dog Behavior from Visual Data

Abstract:
- Task: directly modeling a visually intelligent agent
- DECADE: a dataset of ego-centric videos from a dog's perspective
- Representation can generalize to other domains

Introduction:
- Visual intelligence: understanding visual data to the extent that an agent can take actions and perform tasks in the visual world
- Goal is to learn to act like the visually intelligent agent
- Using a dog, have a specific dataset
- Three main problems: learn to act like a dog, learn to plan like a dog, do representation learning

Related Work:
- There's no work in this exact area, lots of similar work in other areas
- These pieces range around the idea of motivation prediction and appearance prediction
- Includes topics like supervised learning, inverse reinforcement learning etc.

Dataset:
-DECADE is a dataset of ego-centric dog video and joint movements
- Used a GoPro camera 
- Outdoor and indoor scenes

Acting like a dog:
- Model the future images the dog sees based on the previous images
- Classification problem
- Encoder, decoder problem with a CNN and LSTM
- Decoder outputs models of 6 actions per timestep

Planning like a dog:
- Plan a sequence of steps that the dog would use to get from first frame to second frame
- Trying to predict an action sequence

Learning from a dog:
- Learning image representations, using ResNet

Experiments:
- Evaluation based on accuracy of predictions
- Implementation uses kmeans, quaternion angles
- Evaluation based on class accuracy and perplexity

Conclusion:
- First step towards end-to-end modeling
